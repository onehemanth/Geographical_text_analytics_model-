{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP8uhyv+7PbYd+Z5iQM1WoA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# TextToLocation"],"metadata":{"id":"dTiOP9AL_xve"}},{"cell_type":"code","source":["!export LC_CTYPE=en_US.UTF-8"],"metadata":{"id":"zwNlsBx437z8","executionInfo":{"status":"ok","timestamp":1688462125212,"user_tz":-330,"elapsed":3,"user":{"displayName":"Hemanth Yarlagadda","userId":"09531359917931081587"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## Requirements"],"metadata":{"id":"OBTfZf9VBe_8"}},{"cell_type":"code","source":["# Get the model\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"azFO-zX6Betf","executionInfo":{"status":"ok","timestamp":1688462143234,"user_tz":-330,"elapsed":17652,"user":{"displayName":"Hemanth Yarlagadda","userId":"09531359917931081587"}},"outputId":"be0020f0-6d8c-4651-c37d-455c7e05c4b2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Pre trained model\n","!unzip '/content/drive/MyDrive/Trained_Model.zip' -d '/content/Trained_Model'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcC2QGK4G_u2","executionInfo":{"status":"ok","timestamp":1688462145318,"user_tz":-330,"elapsed":2087,"user":{"displayName":"Hemanth Yarlagadda","userId":"09531359917931081587"}},"outputId":"0b682107-631f-41b6-b695-e3dc35c44d20"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/Trained_Model.zip\n","   creating: /content/Trained_Model/content/Trained Model/\n","   creating: /content/Trained_Model/content/Trained Model/attribute_ruler/\n","  inflating: /content/Trained_Model/content/Trained Model/attribute_ruler/patterns  \n","   creating: /content/Trained_Model/content/Trained Model/lemmatizer/\n","   creating: /content/Trained_Model/content/Trained Model/lemmatizer/lookups/\n","  inflating: /content/Trained_Model/content/Trained Model/lemmatizer/lookups/lookups.bin  \n","   creating: /content/Trained_Model/content/Trained Model/tagger/\n","  inflating: /content/Trained_Model/content/Trained Model/tagger/model  \n","  inflating: /content/Trained_Model/content/Trained Model/tagger/cfg  \n","  inflating: /content/Trained_Model/content/Trained Model/config.cfg  \n","   creating: /content/Trained_Model/content/Trained Model/senter/\n","  inflating: /content/Trained_Model/content/Trained Model/senter/model  \n"," extracting: /content/Trained_Model/content/Trained Model/senter/cfg  \n","   creating: /content/Trained_Model/content/Trained Model/tok2vec/\n","  inflating: /content/Trained_Model/content/Trained Model/tok2vec/model  \n"," extracting: /content/Trained_Model/content/Trained Model/tok2vec/cfg  \n","   creating: /content/Trained_Model/content/Trained Model/vocab/\n","  inflating: /content/Trained_Model/content/Trained Model/vocab/vectors  \n","  inflating: /content/Trained_Model/content/Trained Model/vocab/lookups.bin  \n"," extracting: /content/Trained_Model/content/Trained Model/vocab/vectors.cfg  \n","  inflating: /content/Trained_Model/content/Trained Model/vocab/key2row  \n","  inflating: /content/Trained_Model/content/Trained Model/vocab/strings.json  \n","  inflating: /content/Trained_Model/content/Trained Model/tokenizer  \n","   creating: /content/Trained_Model/content/Trained Model/ner/\n","  inflating: /content/Trained_Model/content/Trained Model/ner/moves  \n","  inflating: /content/Trained_Model/content/Trained Model/ner/model  \n","  inflating: /content/Trained_Model/content/Trained Model/ner/cfg  \n","  inflating: /content/Trained_Model/content/Trained Model/meta.json  \n","   creating: /content/Trained_Model/content/Trained Model/parser/\n","  inflating: /content/Trained_Model/content/Trained Model/parser/moves  \n","  inflating: /content/Trained_Model/content/Trained Model/parser/model  \n","  inflating: /content/Trained_Model/content/Trained Model/parser/cfg  \n"]}]},{"cell_type":"markdown","source":["#Production line code"],"metadata":{"id":"Elr93pckr1Sa"}},{"cell_type":"code","source":["!pip install geopandas"],"metadata":{"id":"XhI0wDWp2WD_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688462152491,"user_tz":-330,"elapsed":4241,"user":{"displayName":"Hemanth Yarlagadda","userId":"09531359917931081587"}},"outputId":"42dc0828-6100-4f87-ff29-0f7b5b2892a8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (0.13.2)\n","Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.9.4.post1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (23.1)\n","Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.5.3)\n","Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.6.0)\n","Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.1)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (23.1.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (2023.5.7)\n","Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (8.1.3)\n","Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.1.1)\n","Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (0.7.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2022.7.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (1.22.4)\n"]}]},{"cell_type":"code","source":["import spacy\n","import geopy\n","from geopy.geocoders import Nominatim\n","import requests\n","import csv\n","import geopandas as gpd\n","import pandas as pd\n","import zipfile"],"metadata":{"id":"IXgorKbcIZo_","executionInfo":{"status":"ok","timestamp":1688462165790,"user_tz":-330,"elapsed":13308,"user":{"displayName":"Hemanth Yarlagadda","userId":"09531359917931081587"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class TextToLocation:\n","  def __init__(self, model_path):\n","    \"\"\"\n","    model_path: Path of the pre-trained model\n","    \"\"\"\n","    self.model = spacy.load(model_path)\n","\n","  def get_contents(*args):\n","    contents = []\n","    for input in args:\n","        # If the input is a file path, open the file and append its contents to the list of contents\n","        if isinstance(input, (bytes, str)) and input.endswith('.txt'):\n","            with open(input, 'r') as f:\n","                file_contents = f.read()\n","                contents = file_contents.split('\\n')\n","\n","        # If the input is a ZIP file, extract the contents of its text files and append them to the list of contents\n","        elif isinstance(input, (bytes, str)) and input.endswith('.zip'):\n","            with zipfile.ZipFile(input, 'r') as z:\n","                for filename in z.namelist():\n","                    if filename.endswith('.txt'):\n","                        contents.append(z.read(filename).decode())\n","\n","        # If the input is a string, append it to the list of contents\n","        elif isinstance(input, str):\n","            contents.append(input)\n","\n","    return contents\n","\n","\n","  # Create a output table\n","  def create_table(self, contents, filename=\"output.csv\", hasLabels=True):\n","    \"\"\"\n","    Gives out a csv file with Name, Date, Time, Area, City, District, State,\n","    Country as Column names\n","    \"\"\"\n","    # Dictionary to store data\n","    table = {\"NAME\":[], \"DATE\":[], \"TIME\":[], \"AREA\":[], \"CITY\": [],\n","            \"DISTRICT\":[], \"STATE\":[], \"COUNTRY\":[], \"ORGANISATION\":[], \"INCIDENT\":[]}\n","\n","    if hasLabels:\n","      for d in content:\n","        # Single sample\n","        row = {\"NAME\":[], \"DATE\":[], \"TIME\":[], \"AREA\":[], \"CITY\": [],\n","            \"DISTRICT\":[], \"STATE\":[], \"COUNTRY\":[], \"ORGANISATION\":[], \"INCIDENT\":[]}\n","\n","        text = d\n","        pred = self.model(text)\n","        for ent in pred.ents:\n","          row[ent.label_].append(ent.text)\n","\n","        # Append sample to table\n","        for k in table:\n","          table[k].append(row[k])\n","    else:\n","      for d in data:\n","        # Single sample\n","        row = {\"NAME\":[], \"DATE\":[], \"TIME\":[], \"AREA\":[], \"CITY\": [],\n","            \"DISTRICT\":[], \"STATE\":[], \"COUNTRY\":[], \"ORGANISATION\":[], \"INCIDENT\":[]}\n","\n","        pred = self.model(d)\n","        for ent in pred.ents:\n","          row[ent.label_].append(ent.text)\n","\n","        # Append sample to table\n","        for k in table:\n","          table[k].append(row[k])\n","\n","    df = pd.DataFrame(table)\n","\n","    df.to_csv(filename)\n","    return df\n","    def destrip_table(df):\n","      #Removing \"[]\" from table\n","      df = df.apply(lambda x: x.astype(str).str.strip(\"[]\"))\n","      return df\n","  # Geocoding of CSV by concatenating different entities\n","  def geocode(in_file):\n","    with open(in_file, 'r', encoding=\"utf-8\") as f_in:\n","        csv_reader = csv.reader(f_in)\n","\n","        # we are using OpenStreetmaps Geocoder\n","        geolocator = Nominatim(user_agent=\"Garudaltics\")\n","\n","        # Removing heading\n","        header = next(csv_reader)\n","        #header = destrip_table(pd.DataFrame(header)).iloc[0].tolist()\n","        with open('geocoded_data.csv', 'w', newline='') as f_out:\n","            csv_writer = csv.writer(f_out)\n","\n","            # Adding lat, long headings\n","            header.append(\"latitude\")\n","            header.append(\"longitude\")\n","            csv_writer.writerow(header)\n","\n","            # Concatenating Area, city, district, State, and Country\n","            for row in csv_reader:\n","                loc = f\"{row[4]} {row[5]} {row[6]} {row[7]} {row[8]}\"\n","                loc = loc.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\")\n","                # Geocoder on loc\n","                location = geolocator.geocode(loc, timeout=10000)\n","\n","                # Removing low level entities one by one to get geocoding\n","                if not location:\n","                    loc1 = f\"{row[5]} {row[6]} {row[7]}\"\n","                    loc1 = loc1.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\")\n","                    location = geolocator.geocode(loc1, timeout=10000)\n","\n","                    if not location:\n","                        loc2 = f\"{row[6]} {row[7]}\"\n","                        loc2 = loc2.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\")\n","                        location = geolocator.geocode(loc2, timeout=10000)\n","\n","                        if not location:\n","                            loc3 = row[7]\n","                            loc3 = loc3.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\")\n","                            location = geolocator.geocode(loc3, timeout=10000)\n","\n","                            if not location:\n","                                #pass\n","                                print(\"Location not found\")\n","                                continue\n","                            else:\n","                                print((location.latitude, location.longitude))\n","                        else:\n","                            print((location.latitude, location.longitude))\n","                    else:\n","                        print((location.latitude, location.longitude))\n","                else:\n","                    print((location.latitude, location.longitude))\n","\n","                # Adding lat, long values to same row\n","                row.append(location.latitude)\n","                row.append(location.longitude)\n","                csv_writer.writerow(row)\n","    print(\"Done.\")\n","\n","  def export(infile):\n","    df = pd.read_csv(infile)\n","    # convert the DataFrame to a GeoDataFrame\n","    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))\n","    gdf.crs = \"EPSG:4326\"\n","    gdf.to_file(\"point_data.shp\", driver=\"ESRI Shapefile\")"],"metadata":{"id":"802xjKhpsMLr","executionInfo":{"status":"ok","timestamp":1688462165790,"user_tz":-330,"elapsed":4,"user":{"displayName":"Hemanth Yarlagadda","userId":"09531359917931081587"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model = TextToLocation('/content/Trained_Model/content/Trained Model')\n","content = model.get_contents('/content/Reports_final_doc.txt')\n","TextToLocation.create_table(model, contents = content,filename=\"output.csv\")\n","TextToLocation.geocode(\"/content/output.csv\")\n","TextToLocation.export(\"/content/geocoded_data.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"22sFCSTE3K2b","executionInfo":{"status":"ok","timestamp":1688462210944,"user_tz":-330,"elapsed":5700,"user":{"displayName":"Hemanth Yarlagadda","userId":"09531359917931081587"}},"outputId":"d56d785b-a43a-4d7f-c6a5-ad39b38a8858"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["(27.9254195, 96.1647135)\n","(25.5379432, 91.2999102)\n","(23.837628, 91.2805664)\n","Location not found\n","Done.\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-2594018c250b>:143: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n","  gdf.to_file(\"point_data.shp\", driver=\"ESRI Shapefile\")\n","WARNING:fiona._env:Normalized/laundered field name: 'Unnamed: 0' to 'Unnamed_ 0'\n","WARNING:fiona._env:Normalized/laundered field name: 'ORGANISATION' to 'ORGANISATI'\n"]}]}]}